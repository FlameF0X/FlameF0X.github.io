<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Model Card Clone</title>
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom scrollbar for better aesthetics in dark mode */
        ::-webkit-scrollbar {
            width: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #1f2937; /* Gray-800 */
        }
        ::-webkit-scrollbar-thumb {
            background: #4b5563; /* Gray-600 */
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #6b7280; /* Gray-500 */
        }
        /* Custom style for the textarea in edit mode */
        #edit-textarea {
            min-height: 400px;
            resize: vertical;
        }
    </style>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        'hf-blue': '#1c212a',
                        'hf-purple': '#a06af0',
                        'hf-dark-bg': '#0f172a',
                        'hf-card': '#1f2937',
                    },
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    }
                }
            }
        }
    </script>
</head>
<body class="bg-hf-dark-bg text-gray-100 font-sans min-h-screen">

    <div id="app" class="max-w-7xl mx-auto py-6 px-4 sm:px-6 lg:px-8">
        
        <!-- Model Selector and Header Section -->
        <div class="space-y-4">
            <div class="flex justify-start items-center space-x-4">
                <label for="model-selector" class="text-gray-400 text-sm">Select Model:</label>
                <select id="model-selector" onchange="switchModel(this.value)" class="bg-hf-card text-white text-sm font-semibold p-2 rounded-lg border border-gray-700 focus:ring-hf-purple focus:border-hf-purple shadow-md">
                    <option value="gpt2-clone">MyGPT-2-Small-7B (The one I'm presenting)</option>
                    <option value="super-diffusion">ImageGen-XL-v3.2</option>
                    <option value="audio-generator">VoiceSynth-2.0-HiFi</option>
                </select>
            </div>
            
            <div class="flex items-center space-x-2 pb-4 border-b border-gray-700">
                <h1 id="repo-id" class="text-3xl font-extrabold"></h1>
                <span class="text-sm font-semibold text-green-400 bg-green-900/50 px-2 py-0.5 rounded-full">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 inline-block -mt-0.5" viewBox="0 0 20 20" fill="currentColor">
                        <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clip-rule="evenodd" />
                    </svg>
                    Verified
                </span>
            </div>
        </div>


        <!-- Tags and Metadata Row -->
        <div id="tags-container" class="flex flex-wrap gap-2 py-4 border-b border-gray-800">
            <!-- Tags will be inserted here -->
        </div>

        <!-- Navigation Tabs (Community tab removed) -->
        <div class="flex space-x-4 border-b-2 border-hf-purple">
            <button class="px-3 py-2 text-sm font-medium text-gray-100 border-b-2 border-hf-purple">Model Card</button>
            <button class="px-3 py-2 text-sm font-medium text-gray-400 hover:text-gray-100">Files and versions</button>
        </div>

        <!-- Main Content Area -->
        <div class="grid grid-cols-1 lg:grid-cols-3 gap-8 pt-6">
            
            <!-- Left Column: Model Description / README -->
            <div class="lg:col-span-2">
                <div class="flex justify-between items-center mb-4">
                    <h2 class="text-xl font-bold">Model description</h2>
                    <div id="edit-controls">
                        <button id="edit-button" onclick="toggleEditMode()" class="text-sm text-hf-purple hover:text-purple-400 px-3 py-1 bg-hf-card/50 rounded-lg">Edit model card</button>
                    </div>
                </div>
                
                <div id="model-description-wrapper" class="space-y-6 text-gray-300">
                    <!-- Description content will be inserted here (initially as rendered HTML) -->
                </div>
            </div>

            <!-- Right Column: Metadata / Stats / Inference -->
            <div class="lg:col-span-1 space-y-8">
                
                <!-- Downloads/Stats Card -->
                <div class="bg-hf-card p-4 rounded-xl shadow-lg">
                    <div class="flex justify-between items-center mb-4">
                        <div class="text-sm text-gray-400">Downloads last month</div>
                        <span id="downloads-count" class="text-xl font-extrabold text-white"></span>
                    </div>
                    <!-- Mock chart representation -->
                    <div class="h-16 w-full bg-hf-purple/10 flex items-end rounded-lg overflow-hidden">
                        <div class="w-full h-8 bg-hf-purple/50 rounded-t-full relative">
                            <svg class="absolute inset-0 w-full h-full" viewBox="0 0 100 20" preserveAspectRatio="none">
                                <path fill="none" stroke="#a06af0" stroke-width="0.5" stroke-linejoin="round" d="M0 18 L10 10 L20 15 L30 5 L40 12 L50 7 L60 14 L70 11 L80 16 L90 8 L100 13"></path>
                            </svg>
                        </div>
                    </div>
                </div>

                <!-- Safetensors and Config Card -->
                <div class="bg-hf-card p-5 rounded-xl shadow-lg space-y-4">
                    <h3 class="text-lg font-bold flex items-center">
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2 text-yellow-400" viewBox="0 0 20 20" fill="currentColor">
                            <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm-1-7h2v5H9v-5zm0-4h2v2H9V7z" clip-rule="evenodd" />
                        </svg>
                        Safetensors Metadata
                    </h3>
                    <div id="safetensors-metadata" class="space-y-2 text-sm">
                        <!-- Metadata details will be inserted here -->
                    </div>
                </div>

                <!-- Config.json Mock Card -->
                <div class="bg-hf-card p-5 rounded-xl shadow-lg space-y-4">
                    <h3 class="text-lg font-bold flex items-center">
                        <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2 text-cyan-400" viewBox="0 0 20 20" fill="currentColor">
                            <path d="M13.586 3.586a2 2 0 112.828 2.828l-.793.793-2.828-2.828.793-.793zm-3.182 3.182L10 5l-2.586 2.586L9 9.172l4.707 4.707.707.707L15 14.172V15a2 2 0 01-2 2h-1a1 1 0 00-.707.293L10 17.586l-2.293-2.293A1 1 0 007 15v-1a1 1 0 00.293-.707L10 10.172l3.182-3.182z" />
                        </svg>
                        Configuration Details (config.json)
                    </h3>
                    <div id="config-details" class="space-y-2 text-sm text-gray-300">
                        <!-- Config details will be inserted here -->
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        let currentModelId = 'gpt2-clone';

        // Helper function to convert simple markdown/text to HTML (simulating rendering)
        function simpleMarkdownToHtml(markdown) {
            // Convert **bold** to <strong>
            let html = markdown.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            // Convert # Headers to H3
            html = html.replace(/###\s*(.*)/g, '<h3 class="text-xl font-semibold text-white mb-3">$1</h3>');
            // Convert newlines to paragraphs
            html = html.split('\n\n').map(p => {
                if (p.startsWith('<h3')) return p; // Skip wrapping headers
                return `<p class="mb-4">${p.trim()}</p>`;
            }).join('');
            
            // Add a mock-up callout for good measure
             html = html.replace(/\[CALLOUT\]\s*(.*?)\s*\[\/CALLOUT\]/gs, (match, content) => {
                const lines = content.trim().split('\n');
                const title = lines[0].replace(/#\s*/, '');
                const body = lines.slice(1).join('<br>');
                 return `
                    <div class="p-4 bg-gray-800 rounded-lg border border-gray-700 my-4">
                        <h4 class="text-base font-medium text-white mb-1">${title}</h4>
                        <p class="text-sm text-gray-400">${body}</p>
                    </div>
                `;
            });

            return html;
        }

        // Default mock data (using simple markdown format for the description)
        // This simulates the content of hf/README.md
        const defaultDescriptions = {
            "gpt2-clone": `
### My Proprietary Model Overview
**MyGPT-2-Small-7B** is a proprietary, closed-source language model developed for educational and institutional analysis only. It represents a state-of-the-art approach to Causal Language Modeling (CLM), optimized for generating coherent and contextually relevant academic text.

### Model Parameters
The model boasts 7 billion parameters, utilizing a sophisticated Mixture-of-Experts (MoE) routing mechanism that allows it to efficiently handle complex prompts. The architecture is a proprietary variant of the standard Transformer decoder block.

### Training Details
Our model was trained on a unique, curated dataset focusing on literature, history, and scientific texts, specifically designed to avoid common internet biases and maintain an objective tone.

[CALLOUT]
# Key Finding
The model achieved an astonishing 98.7% accuracy on a zero-shot summarization task when tested against a reserved subset of the training data. This performance validates the model's capacity for complex reasoning.
[/CALLOUT]
            `,
            "super-diffusion": `
### ImageGen-XL-v3.2 Overview
**ImageGen-XL-v3.2** is an advanced latent text-to-image diffusion model designed for high-resolution, photorealistic image synthesis. This model excels at generating highly detailed and stylistically diverse artistic content.

### Diffusion Process
It employs a complex **Noise Prediction U-Net** structure, leveraging a large conditional context provided by the T5-XXL language model encoder. The training pipeline focuses on aligning visual concepts with complex natural language prompts.

### VAE Integration
The model includes an integrated VAE (Variational AutoEncoder) optimized for minimal artifact generation, resulting in cleaner and sharper output images compared to previous versions.
            `,
            "audio-generator": `
### VoiceSynth-2.0-HiFi Overview
**VoiceSynth-2.0-HiFi** is a high-fidelity Text-to-Speech (TTS) model capable of synthesizing natural-sounding human speech. It is particularly effective for generating long-form narration and conversational audio.

### Architecture Breakdown
The system uses a two-stage approach: a **Spectrogram Prediction Network** that converts text into mel-spectrograms, followed by a **Neural Vocoder (HiFi-GAN)** that translates the spectrograms into raw audio waveforms.

### Language Support
It includes support for multiple language phonemes (English, Spanish, French) and offers fine-grained control over prosody, pitch, and speaking rate via input conditioning vectors.
            `
        };

        const models = {
            "gpt2-clone": {
                repoId: "my-llm-corp/MyGPT-2-Small-7B",
                downloads: "11,879,196",
                tags: [
                    { label: "Text Generation", color: "bg-blue-600/50" },
                    { label: "Transformers", color: "bg-red-600/50" },
                    { label: "PyTorch", color: "bg-orange-600/50" },
                    { label: "Safetensors", color: "bg-yellow-600/50" },
                    { label: "English", color: "bg-green-600/50" },
                    { label: "license: academic-use-only", color: "bg-gray-600/50" },
                ],
                // Simulates metadata from model/model.safetensors
                safetensors: {
                    modelSize: "7.13 GB",
                    precision: "BF16",
                    tensorType: "BFLOAT",
                },
                // Simulates content of model/config.json
                config: {
                    vocabSize: 50257,
                    nLayer: 32,
                    nHead: 32,
                    nEmbd: 4096,
                    maxPositionEmbeddings: 8192,
                },
            },
            "super-diffusion": {
                repoId: "my-llm-corp/ImageGen-XL-v3.2",
                downloads: "4,520,301",
                tags: [
                    { label: "Text-to-Image", color: "bg-pink-600/50" },
                    { label: "Diffusion", color: "bg-purple-600/50" },
                    { label: "JAX/Flax", color: "bg-yellow-600/50" },
                    { label: "Creative", color: "bg-green-600/50" },
                ],
                safetensors: {
                    modelSize: "15.80 GB",
                    precision: "FP16",
                    tensorType: "FLOAT",
                },
                config: {
                    latentSpace: "512x512",
                    conditioning: "T5-XXL",
                    layers: 64,
                    schedulerType: "DPM++ 2M",
                    vae: "KL-f8",
                },
            },
            "audio-generator": {
                repoId: "my-llm-corp/VoiceSynth-2.0-HiFi",
                downloads: "2,109,887",
                tags: [
                    { label: "TTS", color: "bg-green-600/50" },
                    { label: "Speech Synthesis", color: "bg-blue-600/50" },
                    { label: "TensorFlow", color: "bg-orange-600/50" },
                    { label: "Sound", color: "bg-gray-600/50" },
                ],
                safetensors: {
                    modelSize: "2.55 GB",
                    precision: "FP32",
                    tensorType: "FLOAT",
                },
                config: {
                    sampleRate: "24kHz",
                    speakerEmbeds: 256,
                    durationModel: "Attention-based",
                    vocoder: "HiFi-GAN",
                    maxSeqLength: 128,
                },
            }
        };
        
        // --- Persistence and Edit Functions ---
        
        function getLocalStorageKey(modelId) {
            return `hf_clone_desc_${modelId}`;
        }
        
        // Loads content, simulating reading from the hf/README.md file
        function loadDescription(modelId) {
            const storedContent = localStorage.getItem(getLocalStorageKey(modelId));
            if (storedContent) {
                return storedContent;
            }
            // If no stored content, use the default markdown from the model data
            return defaultDescriptions[modelId];
        }

        // Saves content, simulating writing/committing to the hf/README.md file
        function saveDescription() {
            const textarea = document.getElementById('edit-textarea');
            if (textarea) {
                const markdownContent = textarea.value;
                localStorage.setItem(getLocalStorageKey(currentModelId), markdownContent);
                // Switch back to display mode
                toggleEditMode(false);
                // Re-render the card to show updated content
                renderModelCard();
            }
        }
        
        function toggleEditMode(enable = true) {
            const wrapper = document.getElementById('model-description-wrapper');
            const controls = document.getElementById('edit-controls');
            
            if (enable) {
                const currentContent = loadDescription(currentModelId);
                
                // Set up the textarea for editing
                wrapper.innerHTML = `
                    <textarea id="edit-textarea" class="w-full p-4 bg-hf-card/80 border border-gray-700 rounded-lg text-sm text-gray-200"></textarea>
                `;
                document.getElementById('edit-textarea').value = currentContent;
                
                // Change controls to Save/Cancel
                controls.innerHTML = `
                    <button onclick="saveDescription()" class="text-sm font-semibold text-white px-3 py-1 rounded-lg bg-hf-purple hover:bg-purple-700 transition duration-150 mr-2">Save</button>
                    <button onclick="toggleEditMode(false)" class="text-sm text-gray-400 hover:text-white px-3 py-1 bg-hf-card/50 rounded-lg">Cancel</button>
                `;
            } else {
                // Change controls back to Edit
                controls.innerHTML = `
                    <button id="edit-button" onclick="toggleEditMode(true)" class="text-sm text-hf-purple hover:text-purple-400 px-3 py-1 bg-hf-card/50 rounded-lg">Edit model card</button>
                `;
                // Re-render the model card to show the saved content (or revert to original if canceled)
                renderModelCard();
            }
        }

        // --- Core Rendering Functions ---

        // Function to switch the active model and update the UI
        function switchModel(modelId) {
            currentModelId = modelId;
            // Ensure we are in display mode before rendering the new model
            toggleEditMode(false); 
            renderModelCard();
        }

        // Function to render all data into the HTML
        function renderModelCard() {
            const model = models[currentModelId];
            
            // 1. Header (Repo ID and Downloads)
            document.getElementById('repo-id').textContent = model.repoId;
            document.getElementById('downloads-count').textContent = model.downloads;

            // 2. Tags
            const tagsContainer = document.getElementById('tags-container');
            tagsContainer.innerHTML = model.tags.map(tag => `
                <span class="px-3 py-1 text-xs font-semibold rounded-full ${tag.color} text-white/90">
                    ${tag.label}
                </span>
            `).join('');

            // 3. Model Description (Loads from local storage or default, then converts to HTML)
            const descriptionWrapper = document.getElementById('model-description-wrapper');
            const markdownContent = loadDescription(currentModelId);
            descriptionWrapper.innerHTML = simpleMarkdownToHtml(markdownContent);

            // 4. Safetensors Metadata (Simulated from model/model.safetensors file)
            const safetensorsContainer = document.getElementById('safetensors-metadata');
            safetensorsContainer.innerHTML = `
                ${renderMetadataItem('Model Size', model.safetensors.modelSize)}
                ${renderMetadataItem('Precision', model.safetensors.precision)}
                ${renderMetadataItem('Tensor Type', model.safetensors.tensorType)}
                ${renderMetadataItem('Files Info', '<span class="text-hf-purple hover:underline cursor-pointer">4 Files</span>')}
            `;
            
            // 5. Config Details (Simulated from model/config.json file)
            const configDetailsContainer = document.getElementById('config-details');
            configDetailsContainer.innerHTML = Object.keys(model.config).map(key => {
                const value = model.config[key];
                const readableKey = key.replace(/([A-Z])/g, ' $1').replace(/^./, str => str.toUpperCase());
                return renderMetadataItem(readableKey, typeof value === 'number' ? value.toLocaleString() : value);
            }).join('');
            
            // Update selector if it was rendered from a saved state (initial load)
            const selector = document.getElementById('model-selector');
            if (selector) {
                selector.value = currentModelId;
            }
        }

        // Helper function for consistent metadata rendering
        function renderMetadataItem(label, value) {
            return `
                <div class="flex justify-between items-center border-b border-gray-700/50 pb-1 last:border-b-0 last:pb-0">
                    <span class="text-gray-400">${label}</span>
                    <span class="font-medium text-white">${value}</span>
                </div>
            `;
        }

        // Run the rendering function when the page loads, starting with the default model
        document.addEventListener('DOMContentLoaded', () => {
             // Ensure the dropdown is set to the default model on load
            const selector = document.getElementById('model-selector');
            currentModelId = selector.value || 'gpt2-clone'; 
            renderModelCard();
        });
    </script>
</body>
</html>